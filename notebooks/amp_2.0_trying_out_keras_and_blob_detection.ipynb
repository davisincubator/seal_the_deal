{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f193a5248dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../../../Volumes/dax/seals/TrainSmall2/TrainDotted/42.jpg\n"
     ]
    }
   ],
   "source": [
    "class_names = ['adult_females', 'adult_males', 'juveniles', 'pups', 'subadult_males']\n",
    "\n",
    "my_dir = \"../../../../../../Volumes/dax/seals/TrainSmall2/\"\n",
    "\n",
    "file_names = os.listdir(my_dir + \"Train/\")\n",
    "file_names = sorted(file_names, key=lambda \n",
    "                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files to run on\n",
    "file_names = file_names[1]\n",
    "\n",
    "# dataframe to store results in\n",
    "#coordinates_df = pd.DataFrame(index=file_names, columns=class_names)\n",
    "\n",
    "print(my_dir + \"TrainDotted/\" + file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[161, 143, 131],\n",
       "        [162, 144, 132],\n",
       "        [162, 144, 132],\n",
       "        ..., \n",
       "        [  6,   4, 254],\n",
       "        [  3,   1, 250],\n",
       "        [  6,   5, 251]],\n",
       "\n",
       "       [[158, 142, 129],\n",
       "        [159, 143, 130],\n",
       "        [159, 143, 130],\n",
       "        ..., \n",
       "        [255, 252, 251],\n",
       "        [253, 251, 245],\n",
       "        [  0, 254, 247]],\n",
       "\n",
       "       [[157, 143, 130],\n",
       "        [158, 142, 129],\n",
       "        [159, 143, 130],\n",
       "        ..., \n",
       "        [  1, 254, 253],\n",
       "        [252, 253, 249],\n",
       "        [255, 254, 249]],\n",
       "\n",
       "       ..., \n",
       "       [[  1,   1,   0],\n",
       "        [  0,   0, 255],\n",
       "        [255, 255, 254],\n",
       "        ..., \n",
       "        [  1,   2, 253],\n",
       "        [  1,   1, 255],\n",
       "        [  4,   5,   1]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        [254, 254, 254],\n",
       "        ..., \n",
       "        [255,   0, 250],\n",
       "        [255,   0, 250],\n",
       "        [  1,   2, 252]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        [254, 254, 254],\n",
       "        ..., \n",
       "        [  1,   2, 252],\n",
       "        [253, 255, 246],\n",
       "        [252, 254, 243]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Train and Train Dotted images\n",
    "image_1 = imread(my_dir + \"TrainDotted/\" + '42.jpg')\n",
    "image_2 = imread(my_dir + \"Train/\" + '42.jpg')\n",
    "    \n",
    "cut = np.copy(image_2)\n",
    "        \n",
    "        # absolute difference between Train and Train Dotted\n",
    "        # image_3 = cv2.absdiff(image_1,image_2)\n",
    "\n",
    "image_3 = image_1 - image_2\n",
    "        \n",
    "image_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-32-883cad7ca6e6>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-883cad7ca6e6>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    image_1 = imread(my_dir + \"TrainDotted/\" + '42.jpg')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "for filename in file_names:\n",
    "    \n",
    "    if \".\" not in filename:\n",
    "    \n",
    "        # read the Train and Train Dotted images\n",
    "        image_1 = imread(my_dir + \"TrainDotted/\" + '42.jpg')\n",
    "        image_2 = imread(my_dir + \"Train/\" + '42.jpg')\n",
    "    \n",
    "        cut = np.copy(image_2)\n",
    "        \n",
    "        # absolute difference between Train and Train Dotted\n",
    "        # image_3 = cv2.absdiff(image_1,image_2)\n",
    "    \n",
    "        image_3 = image_1 - image_2\n",
    "        \n",
    "        image_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "    # mask out blackened regions from Train Dotted\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 20] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "    \n",
    "    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "    mask_2[mask_2 < 20] = 0\n",
    "    mask_2[mask_2 > 0] = 255\n",
    "    \n",
    "    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n",
    "    \n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n",
    "    \n",
    "    adult_males = []\n",
    "    subadult_males = []\n",
    "    pups = []\n",
    "    juveniles = []\n",
    "    adult_females = [] \n",
    "    \n",
    "    image_circles = image_1\n",
    "    \n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        g,b,r = image_1[int(y)][int(x)][:]\n",
    "        \n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if r > 200 and g < 50 and b < 50: # RED\n",
    "            adult_males.append((int(x),int(y)))\n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (0,0,255), 10) \n",
    "        elif r > 200 and g > 200 and b < 50: # MAGENTA\n",
    "            subadult_males.append((int(x),int(y))) \n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (250,10,250), 10)\n",
    "        elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n",
    "            pups.append((int(x),int(y)))\n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (20,180,35), 10)\n",
    "        elif r < 100 and  100 < g and b < 100: # BLUE\n",
    "            juveniles.append((int(x),int(y))) \n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (180,60,30), 10)\n",
    "        elif r < 150 and g < 50 and b < 100:  # BROWN\n",
    "            adult_females.append((int(x),int(y)))\n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (0,42,84), 10)  \n",
    "            \n",
    "        cv2.rectangle(cut, (int(x)-112,int(y)-112),(int(x)+112,int(y)+112), 0,-1)\n",
    "            \n",
    "    coordinates_df[\"adult_males\"][filename] = adult_males\n",
    "    coordinates_df[\"subadult_males\"][filename] = subadult_males\n",
    "    coordinates_df[\"adult_females\"][filename] = adult_females\n",
    "    coordinates_df[\"juveniles\"][filename] = juveniles\n",
    "    coordinates_df[\"pups\"][filename] = pups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
