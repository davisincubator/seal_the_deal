{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['adult_females', 'adult_males', 'juveniles', 'pups', 'subadult_males']\n",
    "\n",
    "my_dir = \"/Volumes/dax/seals/Kaggle-NOAA-SeaLions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklist_fin = open(my_dir + 'MismatchedTrainImages.txt')\n",
    "\n",
    "blacklist_ws = blacklist_fin.readlines()\n",
    "blacklist = []\n",
    "for i in blacklist_ws:\n",
    "    blacklist.append(i.strip() + '.jpg')\n",
    "    \n",
    "blacklist.append('train.csv')\n",
    "\n",
    "#print(blacklist[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir(my_dir + \"Train/\")\n",
    "file_names = sorted(file_names, key=lambda \n",
    "                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files to run on\n",
    "file_names = file_names[0:1]\n",
    "\n",
    "# dataframe to store results in\n",
    "coordinates_df = pd.DataFrame(index=file_names, columns=class_names)\n",
    "\n",
    "#print(file_names[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "for filename in file_names:\n",
    "    if filename in blacklist:\n",
    "        file_names.remove(filename)\n",
    "    else:\n",
    "        # read the Train and Train Dotted images\n",
    "        image_1 = cv2.imread(my_dir + \"/TrainDotted/\" + filename)\n",
    "        image_2 = cv2.imread(my_dir + \"/Train/\" + filename)\n",
    "\n",
    "        cut = np.copy(image_2)\n",
    "\n",
    "        # absolute difference between Train and Train Dotted\n",
    "        image_3 = cv2.absdiff(image_1,image_2)\n",
    "\n",
    "    # mask out blackened regions from Train Dotted\n",
    "        mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "        mask_1[mask_1 < 20] = 0\n",
    "        mask_1[mask_1 > 0] = 255\n",
    "\n",
    "        mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "        mask_2[mask_2 < 20] = 0\n",
    "        mask_2[mask_2 > 0] = 255\n",
    "\n",
    "        image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "        image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n",
    "\n",
    "        # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "        image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect blobs\n",
    "        blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n",
    "\n",
    "        adult_males = []\n",
    "        subadult_males = []\n",
    "        pups = []\n",
    "        juveniles = []\n",
    "        adult_females = [] \n",
    "\n",
    "        image_circles = image_1\n",
    "\n",
    "        for blob in blobs:\n",
    "            # get the coordinates for each blob\n",
    "            y, x, s = blob\n",
    "            # get the color of the pixel from Train Dotted in the center of the blob\n",
    "            g,b,r = image_1[int(y)][int(x)][:]\n",
    "\n",
    "            # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "            if r > 200 and g < 50 and b < 50: # RED\n",
    "                adult_males.append((int(x),int(y)))\n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (0,0,255), 10) \n",
    "            elif r > 200 and g > 200 and b < 50: # MAGENTA\n",
    "                subadult_males.append((int(x),int(y))) \n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (250,10,250), 10)\n",
    "            elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n",
    "                pups.append((int(x),int(y)))\n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (20,180,35), 10)\n",
    "            elif r < 100 and  100 < g and b < 100: # BLUE\n",
    "                juveniles.append((int(x),int(y))) \n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (180,60,30), 10)\n",
    "            elif r < 150 and g < 50 and b < 100:  # BROWN\n",
    "                adult_females.append((int(x),int(y)))\n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (0,42,84), 10)  \n",
    "\n",
    "            cv2.rectangle(cut, (int(x)-112,int(y)-112),(int(x)+112,int(y)+112), 0,-1)\n",
    "\n",
    "        coordinates_df[\"adult_males\"][filename] = adult_males\n",
    "        coordinates_df[\"subadult_males\"][filename] = subadult_males\n",
    "        coordinates_df[\"adult_females\"][filename] = adult_females\n",
    "        coordinates_df[\"juveniles\"][filename] = juveniles\n",
    "        coordinates_df[\"pups\"][filename] = pups\n",
    "        \n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for filename in file_names:    \n",
    "    image = cv2.imread(my_dir + \"/Train/\" + filename)\n",
    "    for lion_class in class_names:\n",
    "        try:\n",
    "            for coordinates in coordinates_df[lion_class][filename]:\n",
    "                thumb = image[coordinates[1]-32:coordinates[1]+32,coordinates[0]-32:coordinates[0]+32,:]\n",
    "                if np.shape(thumb) == (64, 64, 3):\n",
    "                    x.append(thumb)\n",
    "                    y.append(lion_class)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,np.shape(cut)[0],224):\n",
    "    for j in range(0,np.shape(cut)[1],224):                \n",
    "        thumb = cut[i:i+64,j:j+64,:]\n",
    "        if np.amin(cv2.cvtColor(thumb, cv2.COLOR_BGR2GRAY)) != 0:\n",
    "            if np.shape(thumb) == (64,64,3):\n",
    "                x.append(thumb)\n",
    "                y.append(\"negative\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names.append(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = '2017-06-23_model.h5'#what is the model file named?\n",
    "\n",
    "model = load_model(my_dir + my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_names = os.listdir(my_dir + \"Test/\")\n",
    "test_file_names = sorted(test_file_names, key=lambda \n",
    "                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files to run on\n",
    "#test_file_names = test_file_names[0:1]\n",
    "\n",
    "# dataframe to store results in\n",
    "test_coordinates_df = pd.DataFrame(0,index=test_file_names, columns=class_names)\n",
    "\n",
    "#print(test_file_names[:5])\n",
    "#print(test_coordinates_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-edd1c57bae58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1572\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for filename in test_file_names:\n",
    "    img = cv2.imread(my_dir + \"Test/\"  + filename)\n",
    "\n",
    "    x_test = []\n",
    "\n",
    "    for i in range(0,np.shape(img)[0],64):\n",
    "        for j in range(0,np.shape(img)[1],64):                \n",
    "            thumb = img[i:i+64,j:j+64,:]        \n",
    "            if np.shape(thumb) == (64,64,3):\n",
    "                x_test.append(thumb)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "\n",
    "    y_predicted = model.predict(x_test, verbose=0)\n",
    "\n",
    "    y_predicted = encoder.inverse_transform(y_predicted)\n",
    "\n",
    "    the_counter = Counter(y_predicted)\n",
    "    \n",
    "    #print(the_counter)\n",
    "    \n",
    "    for key in the_counter:\n",
    "        test_coordinates_df.set_value(index = filename, col = key, value = the_counter[key])\n",
    "        \n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           adult_males  subadult_males  adult_females  juveniles  pups\n",
      "0.jpg                6               3             62         28   117\n",
      "1.jpg               38              10            199         95   534\n",
      "2.jpg              324              27            821        401   543\n",
      "3.jpg               69               8            201        157   926\n",
      "4.jpg              215              36            441        235   711\n",
      "5.jpg              116              11            250        139  1093\n",
      "6.jpg               46               5            337        110  1429\n",
      "7.jpg               15               2            102         85   802\n",
      "8.jpg               24               4            160         96   538\n",
      "9.jpg              212              15           1164        303  2154\n",
      "10.jpg              48               5            190         97   840\n",
      "11.jpg              13               1            188        227  1780\n",
      "12.jpg              87              20            498        146   628\n",
      "13.jpg              57               1             45         29   885\n",
      "14.jpg             456              23            813        364  1144\n",
      "15.jpg              69              18            263        109   168\n",
      "16.jpg             106              10            239        132   517\n",
      "17.jpg             213              38            997        303  1119\n",
      "18.jpg              59              11            327         91   863\n",
      "19.jpg             104               8            198        117   488\n",
      "20.jpg              50               5            124         79  1258\n",
      "21.jpg              40               5            150         91   216\n",
      "22.jpg              53               8            255        113   364\n",
      "23.jpg              77              11            306        166   580\n",
      "24.jpg             481              60            509        310   237\n",
      "25.jpg              51              14            113         91   321\n",
      "26.jpg              49               5            226        129   859\n",
      "27.jpg              51               8            295        230  1402\n",
      "28.jpg              41               1             95        133  1024\n",
      "29.jpg              75               5            190         96   256\n",
      "...                ...             ...            ...        ...   ...\n",
      "18606.jpg            0               0              0          0     0\n",
      "18607.jpg            0               0              0          0     0\n",
      "18608.jpg            0               0              0          0     0\n",
      "18609.jpg            0               0              0          0     0\n",
      "18610.jpg            0               0              0          0     0\n",
      "18611.jpg            0               0              0          0     0\n",
      "18612.jpg            0               0              0          0     0\n",
      "18613.jpg            0               0              0          0     0\n",
      "18614.jpg            0               0              0          0     0\n",
      "18615.jpg            0               0              0          0     0\n",
      "18616.jpg            0               0              0          0     0\n",
      "18617.jpg            0               0              0          0     0\n",
      "18618.jpg            0               0              0          0     0\n",
      "18619.jpg            0               0              0          0     0\n",
      "18620.jpg            0               0              0          0     0\n",
      "18621.jpg            0               0              0          0     0\n",
      "18622.jpg            0               0              0          0     0\n",
      "18623.jpg            0               0              0          0     0\n",
      "18624.jpg            0               0              0          0     0\n",
      "18625.jpg            0               0              0          0     0\n",
      "18626.jpg            0               0              0          0     0\n",
      "18627.jpg            0               0              0          0     0\n",
      "18628.jpg            0               0              0          0     0\n",
      "18629.jpg            0               0              0          0     0\n",
      "18630.jpg            0               0              0          0     0\n",
      "18631.jpg            0               0              0          0     0\n",
      "18632.jpg            0               0              0          0     0\n",
      "18633.jpg            0               0              0          0     0\n",
      "18634.jpg            0               0              0          0     0\n",
      "18635.jpg            0               0              0          0     0\n",
      "\n",
      "[18636 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "protect_df = test_coordinates_df\n",
    "#print(test_coordinates_df)\n",
    "\n",
    "#del test_coordinates_df['negative']\n",
    "test_coordinates_df = test_coordinates_df[['adult_males', 'subadult_males', 'adult_females', 'juveniles', 'pups']]\n",
    "print(test_coordinates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_coordinates_df.to_csv(my_dir + datetime.date.today().isoformat() + '_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
