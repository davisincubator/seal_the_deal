{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['adult_females', 'adult_males', 'juveniles', 'pups', 'subadult_males']\n",
    "\n",
    "my_dir = \"/Volumes/dax/seals/TrainSmall2/\"\n",
    "\n",
    "file_names = os.listdir(my_dir + \"Train/\")\n",
    "file_names = sorted(file_names, key=lambda \n",
    "                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files to run on\n",
    "file_names = file_names[0:6]\n",
    "\n",
    "# dataframe to store results in\n",
    "coordinates_df = pd.DataFrame(index=file_names, columns=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in file_names:\n",
    "    \n",
    "    # read the Train and Train Dotted images\n",
    "    image_1 = cv2.imread(my_dir + \"/TrainDotted/\" + filename)\n",
    "    image_2 = cv2.imread(my_dir + \"/Train/\" + filename)\n",
    "    \n",
    "    cut = np.copy(image_2)\n",
    "    \n",
    "    # absolute difference between Train and Train Dotted\n",
    "    image_3 = cv2.absdiff(image_1,image_2)\n",
    "    \n",
    "# mask out blackened regions from Train Dotted\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 20] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "    \n",
    "    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "    mask_2[mask_2 < 20] = 0\n",
    "    mask_2[mask_2 > 0] = 255\n",
    "    \n",
    "    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n",
    "    \n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n",
    "    \n",
    "    adult_males = []\n",
    "    subadult_males = []\n",
    "    pups = []\n",
    "    juveniles = []\n",
    "    adult_females = [] \n",
    "    \n",
    "    image_circles = image_1\n",
    "    \n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        g,b,r = image_1[int(y)][int(x)][:]\n",
    "        \n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if r > 200 and g < 50 and b < 50: # RED\n",
    "            adult_males.append((int(x),int(y)))\n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (0,0,255), 10) \n",
    "        elif r > 200 and g > 200 and b < 50: # MAGENTA\n",
    "            subadult_males.append((int(x),int(y))) \n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (250,10,250), 10)\n",
    "        elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n",
    "            pups.append((int(x),int(y)))\n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (20,180,35), 10)\n",
    "        elif r < 100 and  100 < g and b < 100: # BLUE\n",
    "            juveniles.append((int(x),int(y))) \n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (180,60,30), 10)\n",
    "        elif r < 150 and g < 50 and b < 100:  # BROWN\n",
    "            adult_females.append((int(x),int(y)))\n",
    "            cv2.circle(image_circles, (int(x),int(y)), 20, (0,42,84), 10)  \n",
    "            \n",
    "        cv2.rectangle(cut, (int(x)-112,int(y)-112),(int(x)+112,int(y)+112), 0,-1)\n",
    "            \n",
    "    coordinates_df[\"adult_males\"][filename] = adult_males\n",
    "    coordinates_df[\"subadult_males\"][filename] = subadult_males\n",
    "    coordinates_df[\"adult_females\"][filename] = adult_females\n",
    "    coordinates_df[\"juveniles\"][filename] = juveniles\n",
    "    coordinates_df[\"pups\"][filename] = pups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1,figsize=(10,16))\n",
    "ax.imshow(cv2.cvtColor(image_circles, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1,figsize=(10,16))\n",
    "ax.imshow(cv2.cvtColor(cut, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for filename in file_names:    \n",
    "    image = cv2.imread(my_dir + \"/Train/\" + filename)\n",
    "    for lion_class in class_names:\n",
    "        for coordinates in coordinates_df[lion_class][filename]:\n",
    "            thumb = image[coordinates[1]-32:coordinates[1]+32,coordinates[0]-32:coordinates[0]+32,:]\n",
    "            if np.shape(thumb) == (64, 64, 3):\n",
    "                x.append(thumb)\n",
    "                y.append(lion_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,np.shape(cut)[0],224):\n",
    "    for j in range(0,np.shape(cut)[1],224):                \n",
    "        thumb = cut[i:i+64,j:j+64,:]\n",
    "        if np.amin(cv2.cvtColor(thumb, cv2.COLOR_BGR2GRAY)) != 0:\n",
    "            if np.shape(thumb) == (64,64,3):\n",
    "                x.append(thumb)\n",
    "                y.append(\"negative\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names.append(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for lion_class in class_names:\n",
    "    f, ax = plt.subplots(1,10,figsize=(12,1.5))\n",
    "    f.suptitle(lion_class)\n",
    "    axes = ax.flatten()\n",
    "    j = 0\n",
    "    for a in axes:\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for i in range(j,len(x)):\n",
    "            if y[i] == lion_class:\n",
    "                j = i+1\n",
    "                a.imshow(cv2.cvtColor(x[i], cv2.COLOR_BGR2RGB))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(64,64,3)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x, y, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(my_dir + \"/Train/\"  + filename)\n",
    "\n",
    "x_test = []\n",
    "\n",
    "for i in range(0,np.shape(img)[0],64):\n",
    "    for j in range(0,np.shape(img)[1],64):                \n",
    "        thumb = img[i:i+64,j:j+64,:]        \n",
    "        if np.shape(thumb) == (64,64,3):\n",
    "            x_test.append(thumb)\n",
    "\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(x_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = encoder.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Counter(y_predicted).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reference = pd.read_csv(my_dir + \"/Train/\"  + 'train.csv')\n",
    "reference.iloc[:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
